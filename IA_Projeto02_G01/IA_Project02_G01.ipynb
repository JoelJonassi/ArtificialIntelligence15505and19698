{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 - Machine Learning\n",
    "\n",
    "Students: Joel Jonassi 19698\n",
    "        Rui Alves 15505\n",
    "Teacher: Joaquim Silva"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataSet Link : https://www.kaggle.com/datasets/camnugent/california-housing-prices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "For this job we will analyse the California house dataset...\n",
    "\n",
    "Will start with a contextualization about the metrics that we will use to evaluate the models.\n",
    "\n",
    "Note: Underfiting if the training error and error testing high\n",
    "Overfitting if error training is low or accurancy high and error testing low or accurancy high"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Contextualization\n",
    "\n",
    "At this section will make a contextualization about the metrics used in this project to measure the models performance.\n",
    "\n",
    "### RandomForest and DecisionTreeClassifier Metrics\n",
    "\n",
    "#### Classification accuracy\n",
    "\n",
    "The classification accuracy is the ratio of number of correct predictions to the total number of input samples.\n",
    "This metric works well only if there are equal number of samples belonging to each class.\n",
    "\n",
    "According to the \"https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234\", says that if we consider that there are 98% samples of class A and 2% samples of class B in our training set. Then our model can easily get 98% training accuracy by simply predicting every training sample belonging to class A.\n",
    "When the same model is tested on a test set with 60% samples of class A and 40% samples of class B, then the test accuracy would drop down to 60%. Classification Accuracy is great, but gives us the false sense of achieving high accuracy.\n",
    "\n",
    "![Result](img/ClassificationAccuracy.png)\n",
    "\n",
    "\n",
    "#### Confusion Matrix\n",
    "\n",
    "Confusion Matrix as the name suggests gives us a matrix as output and describes the complete performance of the model.\n",
    "There are 4 important terms :\n",
    "\n",
    "* True Positives : The cases in which we predicted YES and the actual output was also YES.\n",
    "* True Negatives : The cases in which we predicted NO and the actual output was NO.\n",
    "* False Positives : The cases in which we predicted YES and the actual output was NO.\n",
    "* False Negatives : The cases in which we predicted NO and the actual output was YES.\n",
    "Accuracy for the matrix can be calculated by taking average of the values lying across the “main diagonal”.\n",
    "\n",
    "![Result](img/ConfusionMatrix.png)\n",
    "\n",
    "\n",
    "#### F1 Score\n",
    "\n",
    "F1 Score is used to measure a test’s accuracy\n",
    "\n",
    "F1 Score is the Harmonic Mean between precision and recall. The range for F1 Score is [0, 1]. It tells you how precise your classifier is (how many instances it classifies correctly), as well as how robust it is (it does not miss a significant number of instances).\n",
    "\n",
    "High precision but lower recall, gives you an extremely accurate, but it then misses a large number of instances that are difficult to classify. The greater the F1 Score, the better is the performance of our model. Mathematically, it can be expressed as :\n",
    "\n",
    "\n",
    "F1 Score tries to find the balance between precision and recall.\n",
    "\n",
    "![Result](img/F1Score.png)\n",
    "\n",
    "\n",
    "Precision : It is the number of correct positive results divided by the number of positive results predicted by the classifier.\n",
    "\n",
    "![Result](img/F1ScorePrecision.png)\n",
    "\n",
    "Recall : It is the number of correct positive results divided by the number of all relevant samples (all samples that should have been identified as positive).\n",
    "\n",
    "![Result](img/F1ScoreRecall.png)\n",
    "\n",
    "\n",
    "#### Mean Absolute Error\n",
    "Mean Absolute Error is the average of the difference between the Original Values and the Predicted Values. It gives us the measure of how far the predictions were from the actual output. However, they don’t gives us any idea of the direction of the error i.e. whether we are under predicting the data or over predicting the data. Mathematically, it is represented as :\n",
    "\n",
    "![Result](img/MeanAbsoluteError.pngg)\n",
    "\n",
    "The closer MAE is to 0, the more accurate the model is.\n",
    "\n",
    "#### Mean Squared Error\n",
    "Mean Squared Error(MSE) is quite similar to Mean Absolute Error, the only difference being that MSE takes the average of the square of the difference between the original values and the predicted values. The advantage of MSE being that it is easier to compute the gradient, whereas Mean Absolute Error requires complicated linear programming tools to compute the gradient. As, we take square of the error, the effect of larger errors become more pronounced then smaller error, hence the model can now focus more on the larger errors.\n",
    "\n",
    "![Result](img/MeanSquaredError.pngg)\n",
    "\n",
    "\n",
    "\n",
    "### K-Means Metrics\n",
    "For cluster evaluation we use the following metrics:\n",
    "* 1\n",
    "* 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Associations Rules Metrics\n",
    "\n",
    "In the same way as we do above, we will make a contextualization of the metrics used in this project to evaluate the the model created with Apriori Algorithms.\n",
    "\n",
    "* Confidence ...\n",
    "\n",
    "* Suport ...\n",
    "\n",
    "* Lift ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, mean_absolute_error, mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from mlxtend.frequent_patterns import association_rules, apriori\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from apyori import apriori\n",
    "from sklearn import tree\n",
    "from kneed import KneeLocator\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSet reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/housingDataPrepare.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objetives:\n",
    " * Try do predict how far the house is from the beach."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "We consider 10 dataset attributes important to train the model to predict how far the house is near form the beach.\n",
    "From the 10 attributes, we used 9 for testing and 1 for the model to predict the target:\n",
    "* latitude and longitude - we use this two variables to helps ous finding the location of the houses.\n",
    "* house_median_age - this attribute helps our model to predict the age of the house.\n",
    "* total_rooms and total_bedrooms- we find these variables important to train the model because can tells ous how many rooms are near to the beach, as we know there are more houses/rooms for tourism near to the beach.\n",
    "* population - can have a correlation between population and proximity to the beach.\n",
    "* house_hold - we assume that the household can have influence of proximity to the beach or not.\n",
    "* median_income and median_house_value - these two variables we assume that are essential to predict if the house is near the beach, because people with with higher purchasing power are more likely to live there due to the cost of living in these areas.\n",
    "* ocean_proximity - This is the target attribute, we will use two algorithms to predict the ocean proximity namely Decision Random Forest Algorithm and Tree Classifier.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean') \n",
    "data = df.iloc[: , :-3] # Ignore last 3 columns\n",
    "\n",
    "X = data.iloc[ :, : -1].values # Use all columns except de last one in \"data\"\n",
    "\n",
    "imp.fit(X)\n",
    "X = imp.transform(X)\n",
    "Y = data.iloc[ :, 9].values # Target \n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state=0)\n",
    "\n",
    "#Using random forest classifier\n",
    "classifier = RandomForestClassifier() \n",
    "classifier = classifier.fit(X_train, Y_train) # model creation\n",
    "predicted = classifier.predict(X_test) # model evaluation\n",
    "\n",
    "cols = ['ISLAND', 'NEAR OCEAN', 'NEAR BAY', '<1H OCEAN', 'INLAND']\n",
    "\n",
    "#Results\n",
    "print ('Confusion Matrix :')\n",
    "confm = confusion_matrix(Y_test, predicted, labels=cols)\n",
    "print(confm)\n",
    "print('Accuracy Score :', accuracy_score(Y_test, predicted))\n",
    "print('Report : ')\n",
    "print(classification_report(Y_test, predicted, labels=cols, zero_division=0))\n",
    "\n",
    "df_cm = DataFrame(confm, index=cols, columns=cols)\n",
    "ax = sns.heatmap(df_cm, cmap='Oranges', annot=True, fmt=\"d\")\n",
    "\n",
    "\n",
    "conv_to_num = {\n",
    "    'ISLAND': 1,\n",
    "    'NEAR OCEAN': 2,\n",
    "    'NEAR BAY': 3,\n",
    "    '<1H OCEAN': 4,\n",
    "    'INLAND': 5\n",
    "}\n",
    "\n",
    "def convert_num(name):\n",
    "    return conv_to_num[name]\n",
    "\n",
    "mae_y_true = list(map(convert_num, Y_test))\n",
    "mae_y_pred = list(map(convert_num, predicted))\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error(mae_y_true, mae_y_pred)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC = DecisionTreeClassifier().fit(X_train, Y_train) # model creation\n",
    "predicted = DTC.predict(X_test) # model evaluation\n",
    "print('confusion Matrix')\n",
    "confm = confusion_matrix(Y_test, predicted, labels=cols)\n",
    "print(confm)\n",
    "print('Accuracy Score : ', accuracy_score(Y_test, predicted))\n",
    "print(\"Report: \")\n",
    "print(classification_report(Y_test, predicted))\n",
    "\n",
    "mae_y_true = list(map(convert_num, Y_test))\n",
    "mae_y_pred = list(map(convert_num, predicted))\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error(mae_y_true, mae_y_pred)}\")\n",
    "\n",
    "df_cm = DataFrame(confm, index=cols, columns=cols)\n",
    "ax = sns.heatmap(df_cm, cmap='Oranges', annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\"longitude\"\t,\"latitude\",\"housing_median_age\"\t,\"total_rooms\"\t,\"total_bedrooms\"\t,\"population\",\t\"households\",\t\"median_income\"\t,\"median_house_value\"]\n",
    "target_names = \"ocean_proximity\"\n",
    "plt.figure(figsize=(60,60))\n",
    "tree.plot_tree(DTC, filled=True, feature_names=feature_names, class_names=target_names,fontsize=6)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis\n",
    "At this section we will discuss a classification Accuracy of RandomForest and DecisionTreeClassifier Algorithms. \n",
    "\n",
    "### Analysis\n",
    "As we can see in confusion matrix of these two algorithms we observe that the ISLAND in the RandomForest algorithm isn't classified correctly although in DecisionTreeClassifier algorithm it was, even so this algorithm has a worst accuracy score than the RandomForest algorithm.\n",
    "\n",
    "Observing the Mean Absolute Error we can conclude how far we are from classifying everything correctly.\n",
    "\n",
    "RandomForest Confusion Matrix\n",
    "\n",
    "![Result](img/RandomForestConfM.png)\n",
    "\n",
    "\n",
    "Accuracy Score : 0.9751291989664083\n",
    "\n",
    "Mean Absolute Error: 0.03504521963824289\n",
    "\n",
    "\n",
    "DecisionTree Confusion Matrix\n",
    "\n",
    "![Result](img/DecisionTreeConfM.png)\n",
    "\n",
    "Accuracy Score :  0.9748062015503876\n",
    "\n",
    "Mean Absolute Error: 0.036337209302325583"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster with K-Means"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objetives:\n",
    " * Classify the zones where the people with the highest purchasing power reside. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prepare\n",
    "\n",
    "For the algorithm K-Means we just use 3 attributes of the dataset namely:\n",
    "\n",
    "* median_house_value - allow to make clusters with house values.\n",
    "\n",
    "* latitude and longitude - To find where the purchasing power people live.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc(\"figure\", autolayout=True)\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=14,\n",
    "    titlepad=10,\n",
    ")\n",
    "\n",
    "X = df.loc[:, [\"median_house_value\", \"latitude\", \"longitude\"]]\n",
    "X.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elbow\n",
    "cost =[]\n",
    "for i in range(1, 11):\n",
    "    KM = KMeans(n_clusters = i, max_iter = 100)\n",
    "    KM.fit(X)\n",
    "     \n",
    "    # calculates squared error\n",
    "    # for the clustered points\n",
    "    cost.append(KM.inertia_)    \n",
    " \n",
    "# plot the cost against K values\n",
    "plt.plot(range(1, 11), cost, color ='g', linewidth ='3')\n",
    "plt.xlabel(\"Value of K\")\n",
    "plt.ylabel(\"Squared Error (Cost)\")\n",
    "plt.show() # clear the plot\n",
    "\n",
    "kl = KneeLocator(range(1, 11), cost, curve=\"convex\", direction=\"decreasing\" )\n",
    "print(f\"The optimal K is {kl.elbow}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cluster feature\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "\n",
    "X[\"Cluster\"] = kmeans.fit_predict(X)\n",
    "\n",
    "X[\"Cluster\"] = X[\"Cluster\"].astype(\"category\")\n",
    "\n",
    "X.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A scatter plot that shows the geographic distribution of the clusters. It seems like the algorithm has created separate segments for higher-income areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "sns.set(style = \"darkgrid\")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "x  = X[\"latitude\"]\n",
    "y  = X[\"longitude\"]\n",
    "z  = X[\"median_house_value\"]\n",
    "ax.set_xlabel(\"latitude\")\n",
    "ax.set_ylabel(\"longitude\")\n",
    "ax.set_zlabel(\"median_house_value\")\n",
    "ax.scatter(x, y, z)\n",
    "plt.show()\n",
    "\n",
    "#2d\n",
    "#sns.relplot(x=\"longitude\", y=\"latitude\", hue=\"Cluster\", data=X, height=6,);\n",
    "\n",
    "sns.relplot(\n",
    "    x=\"longitude\", y=\"latitude\", hue=\"Cluster\", data=X, height=6,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target in this dataset is median_house_value (median house value). These box-plots show the distribution of the target within each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"median_income\"] = df[\"median_income\"]\n",
    "sns.catplot(x=\"median_income\", y=\"Cluster\", data=X, kind=\"boxen\", height=9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X[\"median_income\"] = df[\"median_income\"]\n",
    "sns.catplot(x=\"median_income\", y=\"Cluster\", data=X, kind=\"boxen\", height=9)\n",
    "## Results Analysis\n",
    "At this section we will discuss the performance of the K-Means algorithm."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Association rules\n",
    "\n",
    "Objetives:\n",
    "* Knowing the income, the age of house and price of house, associate age of house and price of house and income of someone with a house price.\n",
    "\n",
    "### Data Preparation\n",
    "For this algorithm \"Apriori\" we prepare the data for association rules. We Use 3 attributes we consider important to complete our objective.\n",
    "First of all we create a interval of these attributes, labelling each interval by its representing information.\n",
    "For the attribute median_income, we create 5 labels intervals of 2. The labels are: Very Low Income, Low Income, Medium Income, High Income and Very High Income.\n",
    "In excel we use the function below to do this transformation.\n",
    "```bash\n",
    "=SE(H2<=2,\"Very Low Income\",SE(E(2<H2,H2<=4),\"Low Income\",SE(E(4<H2,H2<=6),\"Medium Income\",SE(E(6<H2,H2<=8),\"High Income\",\"Very High Income\"))))\n",
    "```\n",
    "\n",
    "For the attribute housing_median_age we label also with 5  labels namely: Very Recent House, Recent House, Medium Aged House, Older House and Very Older House.\n",
    "\n",
    "```bash\n",
    "=SE(I2<=11,\"Very Recent House\",SE(E(11<I2,I2<=22),\"Recent House\",SE(E(22<I2,I2<=33),\"Medium Aged House\",SE(E(33<I2,I2<=44),\"Older House\",\"Very Older House\"))))\n",
    "```\n",
    "\n",
    "In the same way we label the attribute median_house_value with the following labels: Very Cheap House, Cheap House, Medium Priced House, Expensive House and Very Expensive House.\n",
    "```bash\n",
    "=SE(I2<=90000,\"Very Cheap House\",SE(E(90000<I2,I2<=180000),\"Cheap House\",SE(E(180000<I2,I2<=270000),\"Medium Priced House\",SE(E(270000<I2,I2<=360000),\"Expensive House\",\"Very Expensive House\"))))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ocean_proximity median_income_class median_house_value_class  \\\n",
      "0            NEAR BAY     Very High Icome     Very Expensive House   \n",
      "1            NEAR BAY     Very High Icome          Expensive House   \n",
      "2            NEAR BAY          High Icome          Expensive House   \n",
      "3            NEAR BAY           Low Icome          Expensive House   \n",
      "4            NEAR BAY           Low Icome          Expensive House   \n",
      "...               ...                 ...                      ...   \n",
      "20635          INLAND     Very Low Income         Very Cheap House   \n",
      "20636          INLAND           Low Icome         Very Cheap House   \n",
      "20637          INLAND     Very Low Income              Cheap House   \n",
      "20638          INLAND     Very Low Income         Very Cheap House   \n",
      "20639          INLAND           Low Icome         Very Cheap House   \n",
      "\n",
      "      hosing_median_age_class  \n",
      "0                 Older House  \n",
      "1                Recent House  \n",
      "2            Very Older House  \n",
      "3            Very Older House  \n",
      "4            Very Older House  \n",
      "...                       ...  \n",
      "20635       Medium Aged House  \n",
      "20636            Recent House  \n",
      "20637            Recent House  \n",
      "20638            Recent House  \n",
      "20639            Recent House  \n",
      "\n",
      "[20640 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Data Segragation\n",
    "data = df.iloc[: , :] # All data\n",
    "data = df.iloc[:, 9 :]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for i in range(0, len(data)):\n",
    "    records.append([str(data.values[i, j]) for j in range(0, 4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "association_rules = apriori(records, min_support=0.0045, min_confidence=0.2, min_lift=3, max_length=3) # creation of the model\n",
    "association_results = list(association_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rules mined =  36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Left_Hand_Side</th>\n",
       "      <th>Right_Hand_Side</th>\n",
       "      <th>Support</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very Cheap House</td>\n",
       "      <td>Very Low Income</td>\n",
       "      <td>0.055717</td>\n",
       "      <td>0.427350</td>\n",
       "      <td>3.589952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Very Cheap House</td>\n",
       "      <td>INLAND</td>\n",
       "      <td>0.046705</td>\n",
       "      <td>0.358231</td>\n",
       "      <td>5.948424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>Very Older House</td>\n",
       "      <td>0.043556</td>\n",
       "      <td>0.392576</td>\n",
       "      <td>3.234642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Very Cheap House</td>\n",
       "      <td>INLAND</td>\n",
       "      <td>0.035126</td>\n",
       "      <td>0.269417</td>\n",
       "      <td>3.240535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>Very Older House</td>\n",
       "      <td>0.034399</td>\n",
       "      <td>0.310044</td>\n",
       "      <td>3.422086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Expensive House</td>\n",
       "      <td>High Icome</td>\n",
       "      <td>0.031686</td>\n",
       "      <td>0.256974</td>\n",
       "      <td>3.172221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>High Icome</td>\n",
       "      <td>Very Expensive House</td>\n",
       "      <td>0.031347</td>\n",
       "      <td>0.386962</td>\n",
       "      <td>3.374267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very Expensive House</td>\n",
       "      <td>Very High Icome</td>\n",
       "      <td>0.030136</td>\n",
       "      <td>0.262780</td>\n",
       "      <td>7.860546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Very Cheap House</td>\n",
       "      <td>INLAND</td>\n",
       "      <td>0.029845</td>\n",
       "      <td>0.228911</td>\n",
       "      <td>3.977043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>High Icome</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "      <td>0.021560</td>\n",
       "      <td>0.266148</td>\n",
       "      <td>3.749694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Very High Icome</td>\n",
       "      <td>Very Expensive House</td>\n",
       "      <td>0.018120</td>\n",
       "      <td>0.542029</td>\n",
       "      <td>8.942828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>High Icome</td>\n",
       "      <td>Very Expensive House</td>\n",
       "      <td>0.017248</td>\n",
       "      <td>0.212919</td>\n",
       "      <td>3.512903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Very Cheap House</td>\n",
       "      <td>Very Low Income</td>\n",
       "      <td>0.017054</td>\n",
       "      <td>0.427184</td>\n",
       "      <td>3.588558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Very Cheap House</td>\n",
       "      <td>Very Low Income</td>\n",
       "      <td>0.016279</td>\n",
       "      <td>0.460905</td>\n",
       "      <td>3.871830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Recent House</td>\n",
       "      <td>Very Low Income</td>\n",
       "      <td>0.013324</td>\n",
       "      <td>0.371622</td>\n",
       "      <td>3.121803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Recent House</td>\n",
       "      <td>High Icome</td>\n",
       "      <td>0.012258</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>4.682396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>Very Older House</td>\n",
       "      <td>0.011967</td>\n",
       "      <td>0.502033</td>\n",
       "      <td>4.136507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Medium Priced House</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>0.010901</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>3.379913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>High Icome</td>\n",
       "      <td>Very Expensive House</td>\n",
       "      <td>0.009932</td>\n",
       "      <td>0.702055</td>\n",
       "      <td>6.121847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>High Icome</td>\n",
       "      <td>Very Expensive House</td>\n",
       "      <td>0.009302</td>\n",
       "      <td>0.405920</td>\n",
       "      <td>3.539578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Medium Aged House</td>\n",
       "      <td>High Icome</td>\n",
       "      <td>0.008866</td>\n",
       "      <td>0.265988</td>\n",
       "      <td>3.283493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>Very Older House</td>\n",
       "      <td>0.008866</td>\n",
       "      <td>0.439904</td>\n",
       "      <td>3.624597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>INLAND</td>\n",
       "      <td>Very Cheap House</td>\n",
       "      <td>0.008430</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>3.287148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Very High Icome</td>\n",
       "      <td>Medium Aged House</td>\n",
       "      <td>0.007946</td>\n",
       "      <td>0.237681</td>\n",
       "      <td>7.811687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Very High Icome</td>\n",
       "      <td>Recent House</td>\n",
       "      <td>0.007122</td>\n",
       "      <td>0.213043</td>\n",
       "      <td>10.444697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Very Older House</td>\n",
       "      <td>Very Low Income</td>\n",
       "      <td>0.006734</td>\n",
       "      <td>0.569672</td>\n",
       "      <td>4.785524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Very Expensive House</td>\n",
       "      <td>Very High Icome</td>\n",
       "      <td>0.006492</td>\n",
       "      <td>0.204893</td>\n",
       "      <td>6.128972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>High Icome</td>\n",
       "      <td>Very Expensive House</td>\n",
       "      <td>0.006444</td>\n",
       "      <td>0.624413</td>\n",
       "      <td>5.444819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>Very Expensive House</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.532787</td>\n",
       "      <td>4.645848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Very Recent House</td>\n",
       "      <td>High Icome</td>\n",
       "      <td>0.006153</td>\n",
       "      <td>0.561947</td>\n",
       "      <td>6.936952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Recent House</td>\n",
       "      <td>High Icome</td>\n",
       "      <td>0.005766</td>\n",
       "      <td>0.282660</td>\n",
       "      <td>3.489300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Very Expensive House</td>\n",
       "      <td>Very High Icome</td>\n",
       "      <td>0.005475</td>\n",
       "      <td>0.220273</td>\n",
       "      <td>6.589033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>Very High Icome</td>\n",
       "      <td>0.004942</td>\n",
       "      <td>0.207317</td>\n",
       "      <td>6.201485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>Very Older House</td>\n",
       "      <td>0.004942</td>\n",
       "      <td>0.483412</td>\n",
       "      <td>3.983086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Very Older House</td>\n",
       "      <td>Very Expensive House</td>\n",
       "      <td>0.004845</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>8.226319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Very Older House</td>\n",
       "      <td>Very Expensive House</td>\n",
       "      <td>0.004506</td>\n",
       "      <td>0.715385</td>\n",
       "      <td>6.238081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Left_Hand_Side       Right_Hand_Side   Support  Confidence  \\\n",
       "3       Very Cheap House       Very Low Income  0.055717    0.427350   \n",
       "20      Very Cheap House                INLAND  0.046705    0.358231   \n",
       "2               NEAR BAY      Very Older House  0.043556    0.392576   \n",
       "18      Very Cheap House                INLAND  0.035126    0.269417   \n",
       "22              NEAR BAY      Very Older House  0.034399    0.310044   \n",
       "0        Expensive House            High Icome  0.031686    0.256974   \n",
       "1             High Icome  Very Expensive House  0.031347    0.386962   \n",
       "4   Very Expensive House       Very High Icome  0.030136    0.262780   \n",
       "19      Very Cheap House                INLAND  0.029845    0.228911   \n",
       "5             High Icome             <1H OCEAN  0.021560    0.266148   \n",
       "7        Very High Icome  Very Expensive House  0.018120    0.542029   \n",
       "6             High Icome  Very Expensive House  0.017248    0.212919   \n",
       "23      Very Cheap House       Very Low Income  0.017054    0.427184   \n",
       "30      Very Cheap House       Very Low Income  0.016279    0.460905   \n",
       "32          Recent House       Very Low Income  0.013324    0.371622   \n",
       "9           Recent House            High Icome  0.012258    0.379310   \n",
       "27              NEAR BAY      Very Older House  0.011967    0.502033   \n",
       "25   Medium Priced House              NEAR BAY  0.010901    0.375000   \n",
       "15            High Icome  Very Expensive House  0.009932    0.702055   \n",
       "12            High Icome  Very Expensive House  0.009302    0.405920   \n",
       "8      Medium Aged House            High Icome  0.008866    0.265988   \n",
       "11              NEAR BAY      Very Older House  0.008866    0.439904   \n",
       "21                INLAND      Very Cheap House  0.008430    0.428571   \n",
       "24       Very High Icome     Medium Aged House  0.007946    0.237681   \n",
       "33       Very High Icome          Recent House  0.007122    0.213043   \n",
       "34      Very Older House       Very Low Income  0.006734    0.569672   \n",
       "31  Very Expensive House       Very High Icome  0.006492    0.204893   \n",
       "14            High Icome  Very Expensive House  0.006444    0.624413   \n",
       "13              NEAR BAY  Very Expensive House  0.006298    0.532787   \n",
       "10     Very Recent House            High Icome  0.006153    0.561947   \n",
       "16          Recent House            High Icome  0.005766    0.282660   \n",
       "29  Very Expensive House       Very High Icome  0.005475    0.220273   \n",
       "26              NEAR BAY       Very High Icome  0.004942    0.207317   \n",
       "28              NEAR BAY      Very Older House  0.004942    0.483412   \n",
       "35      Very Older House  Very Expensive House  0.004845    0.943396   \n",
       "17      Very Older House  Very Expensive House  0.004506    0.715385   \n",
       "\n",
       "         Lift  \n",
       "3    3.589952  \n",
       "20   5.948424  \n",
       "2    3.234642  \n",
       "18   3.240535  \n",
       "22   3.422086  \n",
       "0    3.172221  \n",
       "1    3.374267  \n",
       "4    7.860546  \n",
       "19   3.977043  \n",
       "5    3.749694  \n",
       "7    8.942828  \n",
       "6    3.512903  \n",
       "23   3.588558  \n",
       "30   3.871830  \n",
       "32   3.121803  \n",
       "9    4.682396  \n",
       "27   4.136507  \n",
       "25   3.379913  \n",
       "15   6.121847  \n",
       "12   3.539578  \n",
       "8    3.283493  \n",
       "11   3.624597  \n",
       "21   3.287148  \n",
       "24   7.811687  \n",
       "33  10.444697  \n",
       "34   4.785524  \n",
       "31   6.128972  \n",
       "14   5.444819  \n",
       "13   4.645848  \n",
       "10   6.936952  \n",
       "16   3.489300  \n",
       "29   6.589033  \n",
       "26   6.201485  \n",
       "28   3.983086  \n",
       "35   8.226319  \n",
       "17   6.238081  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inspect(association_results):\n",
    "    lhs         = [tuple(result[2][0][0])[0] for result in association_results]\n",
    "    rhs         = [tuple(result[2][0][1])[0] for result in association_results]\n",
    "    support    = [result[1] for result in association_results]\n",
    "    confidence = [result[2][0][2] for result in association_results]\n",
    "    lift       = [result[2][0][3] for result in association_results]\n",
    "    return list(zip(lhs, rhs, support, confidence, lift))\n",
    "\n",
    "output_DataFrame = pd.DataFrame(inspect(association_results), columns = ['Left_Hand_Side', 'Right_Hand_Side', 'Support', 'Confidence', 'Lift'])\n",
    "print(\"Total number of rules mined = \" , len(association_results))\n",
    "output_DataFrame.nlargest(n = 90, columns = 'Support')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Analysis\n",
    "\n",
    "At this section we will evaluate the Apriori model.\n",
    "\n",
    "As we can the Apriori algorithm, satisfy our objectives to make a association between these three attributes.\n",
    "\n",
    "image result\n",
    "\n",
    "Now we will make a deep evaluation of the model:\n",
    "In evaluating process of the Apriori model we consider the support, confidence and Lift values.\n",
    "\n",
    "Rule: High Income -> Expensive House\n",
    "Suport : \n",
    "Confidence : \n",
    "lift : \n",
    "\n",
    "Due to de dataset length we observe that the creation of candidates at the first time we run the algorithm it took some time, we conclude that if we have many atributes to make a association it require much processing power."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Finally this job ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "4b012d59fd9967520aa1876644e3a9774eee391dbb6584df68e553498820aaf9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
